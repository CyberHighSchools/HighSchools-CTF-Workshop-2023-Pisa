# Internet Festival 2023 - HighSchools CTF Workshop

## [web] hidden_file (14 risoluzioni)

Un file robots.txt viene usato principalmente per gestire il traffico dei crawler(`https://it.wikipedia.org/wiki/Crawler`) verso il tuo sito e solitamente per escludere un file da Google, a seconda del tipo di file.

Visitando il robots.txt del sito indicato dalla challenge si possono vedere i file listati: uno di loro Ã¨ un file testuale che contiene la flag.
